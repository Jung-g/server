{
  "best_global_step": 10000,
  "best_metric": 0.4942812919616699,
  "best_model_checkpoint": "D:\\kobart_finetune\\checkpoint-10000",
  "epoch": 2.955082742316785,
  "eval_steps": 1000,
  "global_step": 10000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02955082742316785,
      "grad_norm": 3.624896287918091,
      "learning_rate": 4.972222222222223e-05,
      "loss": 3.3989,
      "step": 100
    },
    {
      "epoch": 0.0591016548463357,
      "grad_norm": 2.825082540512085,
      "learning_rate": 4.942671394799054e-05,
      "loss": 1.0655,
      "step": 200
    },
    {
      "epoch": 0.08865248226950355,
      "grad_norm": 2.7092039585113525,
      "learning_rate": 4.913120567375887e-05,
      "loss": 0.9381,
      "step": 300
    },
    {
      "epoch": 0.1182033096926714,
      "grad_norm": 2.703911304473877,
      "learning_rate": 4.883569739952719e-05,
      "loss": 0.857,
      "step": 400
    },
    {
      "epoch": 0.14775413711583923,
      "grad_norm": 2.558453321456909,
      "learning_rate": 4.854018912529551e-05,
      "loss": 0.8254,
      "step": 500
    },
    {
      "epoch": 0.1773049645390071,
      "grad_norm": 1.8859518766403198,
      "learning_rate": 4.8244680851063836e-05,
      "loss": 0.7855,
      "step": 600
    },
    {
      "epoch": 0.20685579196217493,
      "grad_norm": 1.8965790271759033,
      "learning_rate": 4.794917257683215e-05,
      "loss": 0.7534,
      "step": 700
    },
    {
      "epoch": 0.2364066193853428,
      "grad_norm": 2.3634729385375977,
      "learning_rate": 4.7653664302600476e-05,
      "loss": 0.7523,
      "step": 800
    },
    {
      "epoch": 0.26595744680851063,
      "grad_norm": 2.173597574234009,
      "learning_rate": 4.73581560283688e-05,
      "loss": 0.7216,
      "step": 900
    },
    {
      "epoch": 0.29550827423167847,
      "grad_norm": 2.1432652473449707,
      "learning_rate": 4.706264775413712e-05,
      "loss": 0.7235,
      "step": 1000
    },
    {
      "epoch": 0.29550827423167847,
      "eval_loss": 0.677421510219574,
      "eval_runtime": 35.3976,
      "eval_samples_per_second": 339.853,
      "eval_steps_per_second": 42.489,
      "step": 1000
    },
    {
      "epoch": 0.32505910165484636,
      "grad_norm": 2.722144365310669,
      "learning_rate": 4.6767139479905444e-05,
      "loss": 0.7054,
      "step": 1100
    },
    {
      "epoch": 0.3546099290780142,
      "grad_norm": 2.02190899848938,
      "learning_rate": 4.647163120567376e-05,
      "loss": 0.69,
      "step": 1200
    },
    {
      "epoch": 0.38416075650118203,
      "grad_norm": 1.9407087564468384,
      "learning_rate": 4.6176122931442084e-05,
      "loss": 0.7023,
      "step": 1300
    },
    {
      "epoch": 0.41371158392434987,
      "grad_norm": 1.9035825729370117,
      "learning_rate": 4.5880614657210405e-05,
      "loss": 0.674,
      "step": 1400
    },
    {
      "epoch": 0.4432624113475177,
      "grad_norm": 1.826081395149231,
      "learning_rate": 4.5585106382978725e-05,
      "loss": 0.6486,
      "step": 1500
    },
    {
      "epoch": 0.4728132387706856,
      "grad_norm": 1.9839261770248413,
      "learning_rate": 4.5289598108747045e-05,
      "loss": 0.6139,
      "step": 1600
    },
    {
      "epoch": 0.5023640661938534,
      "grad_norm": 1.7348641157150269,
      "learning_rate": 4.4994089834515366e-05,
      "loss": 0.6181,
      "step": 1700
    },
    {
      "epoch": 0.5319148936170213,
      "grad_norm": 4.639855861663818,
      "learning_rate": 4.469858156028369e-05,
      "loss": 0.6141,
      "step": 1800
    },
    {
      "epoch": 0.5614657210401891,
      "grad_norm": 1.5698189735412598,
      "learning_rate": 4.440307328605201e-05,
      "loss": 0.5944,
      "step": 1900
    },
    {
      "epoch": 0.5910165484633569,
      "grad_norm": 1.503083348274231,
      "learning_rate": 4.410756501182033e-05,
      "loss": 0.5981,
      "step": 2000
    },
    {
      "epoch": 0.5910165484633569,
      "eval_loss": 0.5732876062393188,
      "eval_runtime": 35.9544,
      "eval_samples_per_second": 334.591,
      "eval_steps_per_second": 41.831,
      "step": 2000
    },
    {
      "epoch": 0.6205673758865248,
      "grad_norm": 1.5834835767745972,
      "learning_rate": 4.3812056737588653e-05,
      "loss": 0.5918,
      "step": 2100
    },
    {
      "epoch": 0.6501182033096927,
      "grad_norm": 1.7866744995117188,
      "learning_rate": 4.3516548463356974e-05,
      "loss": 0.5997,
      "step": 2200
    },
    {
      "epoch": 0.6796690307328606,
      "grad_norm": 1.6769448518753052,
      "learning_rate": 4.32210401891253e-05,
      "loss": 0.5955,
      "step": 2300
    },
    {
      "epoch": 0.7092198581560284,
      "grad_norm": 1.7341792583465576,
      "learning_rate": 4.292553191489362e-05,
      "loss": 0.5946,
      "step": 2400
    },
    {
      "epoch": 0.7387706855791962,
      "grad_norm": 1.4757161140441895,
      "learning_rate": 4.263002364066194e-05,
      "loss": 0.5869,
      "step": 2500
    },
    {
      "epoch": 0.7683215130023641,
      "grad_norm": 1.6741515398025513,
      "learning_rate": 4.233451536643026e-05,
      "loss": 0.5826,
      "step": 2600
    },
    {
      "epoch": 0.7978723404255319,
      "grad_norm": 1.640280842781067,
      "learning_rate": 4.203900709219858e-05,
      "loss": 0.5761,
      "step": 2700
    },
    {
      "epoch": 0.8274231678486997,
      "grad_norm": 1.6830719709396362,
      "learning_rate": 4.17434988179669e-05,
      "loss": 0.565,
      "step": 2800
    },
    {
      "epoch": 0.8569739952718676,
      "grad_norm": 3.429563283920288,
      "learning_rate": 4.144799054373523e-05,
      "loss": 0.5727,
      "step": 2900
    },
    {
      "epoch": 0.8865248226950354,
      "grad_norm": 1.6467856168746948,
      "learning_rate": 4.115248226950355e-05,
      "loss": 0.5624,
      "step": 3000
    },
    {
      "epoch": 0.8865248226950354,
      "eval_loss": 0.5449122786521912,
      "eval_runtime": 36.2465,
      "eval_samples_per_second": 331.894,
      "eval_steps_per_second": 41.494,
      "step": 3000
    },
    {
      "epoch": 0.9160756501182034,
      "grad_norm": 1.8585199117660522,
      "learning_rate": 4.085697399527187e-05,
      "loss": 0.5688,
      "step": 3100
    },
    {
      "epoch": 0.9456264775413712,
      "grad_norm": 1.7897694110870361,
      "learning_rate": 4.056146572104019e-05,
      "loss": 0.561,
      "step": 3200
    },
    {
      "epoch": 0.975177304964539,
      "grad_norm": 1.609880805015564,
      "learning_rate": 4.026595744680851e-05,
      "loss": 0.5593,
      "step": 3300
    },
    {
      "epoch": 1.0047281323877069,
      "grad_norm": 1.800838589668274,
      "learning_rate": 3.997044917257684e-05,
      "loss": 0.5623,
      "step": 3400
    },
    {
      "epoch": 1.0342789598108748,
      "grad_norm": 1.2688478231430054,
      "learning_rate": 3.967494089834515e-05,
      "loss": 0.4855,
      "step": 3500
    },
    {
      "epoch": 1.0638297872340425,
      "grad_norm": 1.6078784465789795,
      "learning_rate": 3.937943262411348e-05,
      "loss": 0.4821,
      "step": 3600
    },
    {
      "epoch": 1.0933806146572105,
      "grad_norm": 1.6009440422058105,
      "learning_rate": 3.90839243498818e-05,
      "loss": 0.4859,
      "step": 3700
    },
    {
      "epoch": 1.1229314420803782,
      "grad_norm": 1.6448534727096558,
      "learning_rate": 3.878841607565012e-05,
      "loss": 0.4745,
      "step": 3800
    },
    {
      "epoch": 1.1524822695035462,
      "grad_norm": 1.516622543334961,
      "learning_rate": 3.8492907801418445e-05,
      "loss": 0.4815,
      "step": 3900
    },
    {
      "epoch": 1.1820330969267139,
      "grad_norm": 1.3806045055389404,
      "learning_rate": 3.819739952718676e-05,
      "loss": 0.4793,
      "step": 4000
    },
    {
      "epoch": 1.1820330969267139,
      "eval_loss": 0.5276880264282227,
      "eval_runtime": 35.5652,
      "eval_samples_per_second": 338.252,
      "eval_steps_per_second": 42.288,
      "step": 4000
    },
    {
      "epoch": 1.2115839243498818,
      "grad_norm": 1.516229271888733,
      "learning_rate": 3.7901891252955086e-05,
      "loss": 0.4895,
      "step": 4100
    },
    {
      "epoch": 1.2411347517730495,
      "grad_norm": 1.4198209047317505,
      "learning_rate": 3.7606382978723406e-05,
      "loss": 0.4724,
      "step": 4200
    },
    {
      "epoch": 1.2706855791962175,
      "grad_norm": 1.7789404392242432,
      "learning_rate": 3.7310874704491727e-05,
      "loss": 0.4777,
      "step": 4300
    },
    {
      "epoch": 1.3002364066193852,
      "grad_norm": 1.6738659143447876,
      "learning_rate": 3.7015366430260054e-05,
      "loss": 0.475,
      "step": 4400
    },
    {
      "epoch": 1.3297872340425532,
      "grad_norm": 1.6398333311080933,
      "learning_rate": 3.671985815602837e-05,
      "loss": 0.4924,
      "step": 4500
    },
    {
      "epoch": 1.3593380614657211,
      "grad_norm": 1.5856014490127563,
      "learning_rate": 3.6424349881796694e-05,
      "loss": 0.4823,
      "step": 4600
    },
    {
      "epoch": 1.3888888888888888,
      "grad_norm": 1.7331887483596802,
      "learning_rate": 3.6128841607565014e-05,
      "loss": 0.4826,
      "step": 4700
    },
    {
      "epoch": 1.4184397163120568,
      "grad_norm": 1.4109785556793213,
      "learning_rate": 3.5833333333333335e-05,
      "loss": 0.4788,
      "step": 4800
    },
    {
      "epoch": 1.4479905437352245,
      "grad_norm": 1.5912727117538452,
      "learning_rate": 3.553782505910166e-05,
      "loss": 0.4785,
      "step": 4900
    },
    {
      "epoch": 1.4775413711583925,
      "grad_norm": 1.4929933547973633,
      "learning_rate": 3.5242316784869975e-05,
      "loss": 0.4799,
      "step": 5000
    },
    {
      "epoch": 1.4775413711583925,
      "eval_loss": 0.521435022354126,
      "eval_runtime": 36.5514,
      "eval_samples_per_second": 329.125,
      "eval_steps_per_second": 41.148,
      "step": 5000
    },
    {
      "epoch": 1.5070921985815602,
      "grad_norm": 1.5209349393844604,
      "learning_rate": 3.49468085106383e-05,
      "loss": 0.4779,
      "step": 5100
    },
    {
      "epoch": 1.5366430260047281,
      "grad_norm": 1.4065327644348145,
      "learning_rate": 3.465130023640662e-05,
      "loss": 0.4679,
      "step": 5200
    },
    {
      "epoch": 1.566193853427896,
      "grad_norm": 1.5677047967910767,
      "learning_rate": 3.435579196217494e-05,
      "loss": 0.4783,
      "step": 5300
    },
    {
      "epoch": 1.5957446808510638,
      "grad_norm": 1.584721326828003,
      "learning_rate": 3.406028368794326e-05,
      "loss": 0.4855,
      "step": 5400
    },
    {
      "epoch": 1.6252955082742315,
      "grad_norm": 1.5582345724105835,
      "learning_rate": 3.3764775413711583e-05,
      "loss": 0.4801,
      "step": 5500
    },
    {
      "epoch": 1.6548463356973995,
      "grad_norm": 1.31545889377594,
      "learning_rate": 3.346926713947991e-05,
      "loss": 0.468,
      "step": 5600
    },
    {
      "epoch": 1.6843971631205674,
      "grad_norm": 1.5322542190551758,
      "learning_rate": 3.317375886524823e-05,
      "loss": 0.4786,
      "step": 5700
    },
    {
      "epoch": 1.7139479905437351,
      "grad_norm": 1.4906437397003174,
      "learning_rate": 3.287825059101655e-05,
      "loss": 0.4786,
      "step": 5800
    },
    {
      "epoch": 1.743498817966903,
      "grad_norm": 1.4270293712615967,
      "learning_rate": 3.258274231678487e-05,
      "loss": 0.4754,
      "step": 5900
    },
    {
      "epoch": 1.773049645390071,
      "grad_norm": 1.6974027156829834,
      "learning_rate": 3.228723404255319e-05,
      "loss": 0.4725,
      "step": 6000
    },
    {
      "epoch": 1.773049645390071,
      "eval_loss": 0.5072804093360901,
      "eval_runtime": 35.4567,
      "eval_samples_per_second": 339.287,
      "eval_steps_per_second": 42.418,
      "step": 6000
    },
    {
      "epoch": 1.8026004728132388,
      "grad_norm": 1.8222646713256836,
      "learning_rate": 3.199172576832151e-05,
      "loss": 0.4901,
      "step": 6100
    },
    {
      "epoch": 1.8321513002364065,
      "grad_norm": 1.4051967859268188,
      "learning_rate": 3.169621749408984e-05,
      "loss": 0.4791,
      "step": 6200
    },
    {
      "epoch": 1.8617021276595744,
      "grad_norm": 1.5794973373413086,
      "learning_rate": 3.140070921985816e-05,
      "loss": 0.4653,
      "step": 6300
    },
    {
      "epoch": 1.8912529550827424,
      "grad_norm": 1.5384538173675537,
      "learning_rate": 3.110520094562648e-05,
      "loss": 0.455,
      "step": 6400
    },
    {
      "epoch": 1.92080378250591,
      "grad_norm": 1.529629111289978,
      "learning_rate": 3.08096926713948e-05,
      "loss": 0.4771,
      "step": 6500
    },
    {
      "epoch": 1.950354609929078,
      "grad_norm": 1.299669861793518,
      "learning_rate": 3.051418439716312e-05,
      "loss": 0.4801,
      "step": 6600
    },
    {
      "epoch": 1.979905437352246,
      "grad_norm": 1.4483646154403687,
      "learning_rate": 3.0218676122931444e-05,
      "loss": 0.4886,
      "step": 6700
    },
    {
      "epoch": 2.0094562647754137,
      "grad_norm": 1.6599024534225464,
      "learning_rate": 2.9923167848699764e-05,
      "loss": 0.4456,
      "step": 6800
    },
    {
      "epoch": 2.0390070921985815,
      "grad_norm": 1.503990888595581,
      "learning_rate": 2.9627659574468088e-05,
      "loss": 0.3864,
      "step": 6900
    },
    {
      "epoch": 2.0685579196217496,
      "grad_norm": 1.398341417312622,
      "learning_rate": 2.933215130023641e-05,
      "loss": 0.3947,
      "step": 7000
    },
    {
      "epoch": 2.0685579196217496,
      "eval_loss": 0.508940577507019,
      "eval_runtime": 36.1485,
      "eval_samples_per_second": 332.794,
      "eval_steps_per_second": 41.606,
      "step": 7000
    },
    {
      "epoch": 2.0981087470449173,
      "grad_norm": 1.419096827507019,
      "learning_rate": 2.9036643026004728e-05,
      "loss": 0.3919,
      "step": 7100
    },
    {
      "epoch": 2.127659574468085,
      "grad_norm": 1.8517948389053345,
      "learning_rate": 2.8741134751773052e-05,
      "loss": 0.3937,
      "step": 7200
    },
    {
      "epoch": 2.157210401891253,
      "grad_norm": 1.5963149070739746,
      "learning_rate": 2.8445626477541372e-05,
      "loss": 0.3968,
      "step": 7300
    },
    {
      "epoch": 2.186761229314421,
      "grad_norm": 1.552960991859436,
      "learning_rate": 2.8150118203309696e-05,
      "loss": 0.4058,
      "step": 7400
    },
    {
      "epoch": 2.2163120567375887,
      "grad_norm": 1.4068015813827515,
      "learning_rate": 2.785460992907802e-05,
      "loss": 0.3988,
      "step": 7500
    },
    {
      "epoch": 2.2458628841607564,
      "grad_norm": 1.4245033264160156,
      "learning_rate": 2.7559101654846336e-05,
      "loss": 0.394,
      "step": 7600
    },
    {
      "epoch": 2.2754137115839246,
      "grad_norm": 1.4177013635635376,
      "learning_rate": 2.726359338061466e-05,
      "loss": 0.4079,
      "step": 7700
    },
    {
      "epoch": 2.3049645390070923,
      "grad_norm": 1.475366473197937,
      "learning_rate": 2.696808510638298e-05,
      "loss": 0.4125,
      "step": 7800
    },
    {
      "epoch": 2.33451536643026,
      "grad_norm": 1.4214979410171509,
      "learning_rate": 2.6672576832151304e-05,
      "loss": 0.4037,
      "step": 7900
    },
    {
      "epoch": 2.3640661938534278,
      "grad_norm": 1.4330618381500244,
      "learning_rate": 2.637706855791962e-05,
      "loss": 0.3877,
      "step": 8000
    },
    {
      "epoch": 2.3640661938534278,
      "eval_loss": 0.5045661926269531,
      "eval_runtime": 35.5913,
      "eval_samples_per_second": 338.004,
      "eval_steps_per_second": 42.258,
      "step": 8000
    },
    {
      "epoch": 2.393617021276596,
      "grad_norm": 1.741356372833252,
      "learning_rate": 2.6081560283687944e-05,
      "loss": 0.3999,
      "step": 8100
    },
    {
      "epoch": 2.4231678486997636,
      "grad_norm": 1.376641035079956,
      "learning_rate": 2.5786052009456268e-05,
      "loss": 0.4059,
      "step": 8200
    },
    {
      "epoch": 2.4527186761229314,
      "grad_norm": 1.577309250831604,
      "learning_rate": 2.549054373522459e-05,
      "loss": 0.4056,
      "step": 8300
    },
    {
      "epoch": 2.482269503546099,
      "grad_norm": 1.507335901260376,
      "learning_rate": 2.5195035460992912e-05,
      "loss": 0.3924,
      "step": 8400
    },
    {
      "epoch": 2.5118203309692673,
      "grad_norm": 1.5036145448684692,
      "learning_rate": 2.4899527186761232e-05,
      "loss": 0.3895,
      "step": 8500
    },
    {
      "epoch": 2.541371158392435,
      "grad_norm": 1.382485032081604,
      "learning_rate": 2.4604018912529553e-05,
      "loss": 0.4046,
      "step": 8600
    },
    {
      "epoch": 2.5709219858156027,
      "grad_norm": 1.4876490831375122,
      "learning_rate": 2.4308510638297873e-05,
      "loss": 0.3973,
      "step": 8700
    },
    {
      "epoch": 2.6004728132387704,
      "grad_norm": 1.5841506719589233,
      "learning_rate": 2.4013002364066196e-05,
      "loss": 0.4199,
      "step": 8800
    },
    {
      "epoch": 2.6300236406619386,
      "grad_norm": 1.6007475852966309,
      "learning_rate": 2.3717494089834517e-05,
      "loss": 0.3968,
      "step": 8900
    },
    {
      "epoch": 2.6595744680851063,
      "grad_norm": 1.1939188241958618,
      "learning_rate": 2.3421985815602837e-05,
      "loss": 0.3955,
      "step": 9000
    },
    {
      "epoch": 2.6595744680851063,
      "eval_loss": 0.5022159218788147,
      "eval_runtime": 35.3142,
      "eval_samples_per_second": 340.656,
      "eval_steps_per_second": 42.589,
      "step": 9000
    },
    {
      "epoch": 2.6891252955082745,
      "grad_norm": 1.42877197265625,
      "learning_rate": 2.3126477541371157e-05,
      "loss": 0.4091,
      "step": 9100
    },
    {
      "epoch": 2.7186761229314422,
      "grad_norm": 1.3845237493515015,
      "learning_rate": 2.283096926713948e-05,
      "loss": 0.391,
      "step": 9200
    },
    {
      "epoch": 2.74822695035461,
      "grad_norm": 1.515821933746338,
      "learning_rate": 2.2535460992907805e-05,
      "loss": 0.3992,
      "step": 9300
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 1.4371572732925415,
      "learning_rate": 2.2239952718676125e-05,
      "loss": 0.3935,
      "step": 9400
    },
    {
      "epoch": 2.8073286052009454,
      "grad_norm": 1.8122133016586304,
      "learning_rate": 2.1944444444444445e-05,
      "loss": 0.4061,
      "step": 9500
    },
    {
      "epoch": 2.8368794326241136,
      "grad_norm": 1.469031572341919,
      "learning_rate": 2.1648936170212765e-05,
      "loss": 0.3977,
      "step": 9600
    },
    {
      "epoch": 2.8664302600472813,
      "grad_norm": 1.5590639114379883,
      "learning_rate": 2.1353427895981086e-05,
      "loss": 0.3997,
      "step": 9700
    },
    {
      "epoch": 2.895981087470449,
      "grad_norm": 1.44382643699646,
      "learning_rate": 2.1057919621749413e-05,
      "loss": 0.405,
      "step": 9800
    },
    {
      "epoch": 2.925531914893617,
      "grad_norm": 1.5445857048034668,
      "learning_rate": 2.0762411347517733e-05,
      "loss": 0.4108,
      "step": 9900
    },
    {
      "epoch": 2.955082742316785,
      "grad_norm": 1.4047322273254395,
      "learning_rate": 2.0466903073286053e-05,
      "loss": 0.3953,
      "step": 10000
    },
    {
      "epoch": 2.955082742316785,
      "eval_loss": 0.4942812919616699,
      "eval_runtime": 35.1446,
      "eval_samples_per_second": 342.3,
      "eval_steps_per_second": 42.795,
      "step": 10000
    }
  ],
  "logging_steps": 100,
  "max_steps": 16920,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 1000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 5,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4762851545088000.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
