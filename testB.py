# local_test_B.py

import cv2
import os

# ğŸ’¡ 1. ìˆ˜ì •ëœ í•µì‹¬ ë¡œì§ê³¼ ì„¤ì •ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
#    ë°©ì‹ Aì˜ CONFIGë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
from model.LSTM.LSTM_video_OOP2B import SignLanguageRecognizer
from model.LSTM.LSTM_video_OOP2A import CONFIG 

# ğŸ’¡ 2. í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©í•  ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
TEST_VIDEO_PATH = "c:\\Users\\bit\\Desktop\\KakaoTalk_20250716_212034817.mp4" # â—€â—€â—€ ë³¸ì¸ì˜ í…ŒìŠ¤íŠ¸ ì˜ìƒ íŒŒì¼ ê²½ë¡œ

def run_streaming_simulation():
    """
    ì„œë²„ ì—†ì´ ë°©ì‹ B(í”„ë ˆì„ ìŠ¤íŠ¸ë¦¬ë°)ì˜ ë¡œì§ì„ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.
    """
    print("--- ë¡œì»¬ í™˜ê²½ì—ì„œ ë°©ì‹ B(ìŠ¤íŠ¸ë¦¬ë°) ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ---")
    
    # 3. ì„œë²„ í™˜ê²½ê³¼ ë™ì¼í•˜ê²Œ CONFIGë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    #    ëª¨ë¸ íŒŒì¼ ê²½ë¡œë¥¼ ë¡œì»¬ í™˜ê²½ì— ë§ê²Œ í™•ì¸í•´ì£¼ì„¸ìš”.
    current_config = CONFIG.copy()
    current_config["MODEL_DIR"] = "C:/Users/bit/Desktop" # â—€â—€â—€ ëª¨ë¸ íŒŒì¼(pt, npy, json ë“±)ì´ ìˆëŠ” í´ë” ê²½ë¡œ

    if not os.path.exists(TEST_VIDEO_PATH):
        print(f"[ì˜¤ë¥˜] í…ŒìŠ¤íŠ¸ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {TEST_VIDEO_PATH}")
        return
    if not os.path.exists(current_config["MODEL_DIR"]):
        print(f"[ì˜¤ë¥˜] ëª¨ë¸ íŒŒì¼ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {current_config['MODEL_DIR']}")
        return

    # 4. (ì‹œë®¬ë ˆì´ì…˜) í´ë¼ì´ì–¸íŠ¸ê°€ ì ‘ì†í•˜ì—¬ Recognizer ì¸ìŠ¤í„´ìŠ¤ê°€ ìƒì„±ë©ë‹ˆë‹¤.
    print("\n[ì‹œë®¬ë ˆì´ì…˜] ìƒˆë¡œìš´ ì‚¬ìš©ìê°€ ì ‘ì†í•˜ì—¬ Recognizerë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
    recognizer = SignLanguageRecognizer(current_config)

    # 5. (ì‹œë®¬ë ˆì´ì…˜) í´ë¼ì´ì–¸íŠ¸ê°€ ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ê³„ì†í•´ì„œ ë³´ëƒ…ë‹ˆë‹¤.
    #    ì´ ê³¼ì •ì€ `/translate/analyze_frames` APIë¥¼ ê³„ì† í˜¸ì¶œí•˜ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤.
    print("[ì‹œë®¬ë ˆì´ì…˜] ë¹„ë””ì˜¤ í”„ë ˆì„ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤... (/analyze_frames í˜¸ì¶œ)")
    
    cap = cv2.VideoCapture(TEST_VIDEO_PATH)
    frame_count = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        frame_count += 1
        # ì„œë²„ì™€ ë™ì¼í•˜ê²Œ í”„ë ˆì„ì„ ë’¤ì§‘ì–´ì¤ë‹ˆë‹¤.
        # routerBì—ì„œ flipì„ ì•ˆí–ˆë‹¤ë©´ ì´ ë¼ì¸ì„ ì£¼ì„ì²˜ë¦¬ í•˜ì„¸ìš”.
        frame = cv2.flip(frame, 1) # routerB.pyì—ì„œ flipì„ í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬
        
        # í•µì‹¬: process_frame()ì„ í˜¸ì¶œí•˜ì—¬ í”„ë ˆì„ì„ í•˜ë‚˜ì”© ì²˜ë¦¬í•©ë‹ˆë‹¤.
        newly_recognized_word = recognizer.process_frame(frame)
        
        # ìƒˆë¡œìš´ ë‹¨ì–´ê°€ ì¸ì‹ë  ë•Œë§ˆë‹¤ ë¡œê·¸ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
        if newly_recognized_word:
            print(f"  > Frame {frame_count}: ìƒˆë¡œìš´ ë‹¨ì–´/ì§€ë¬¸ì ì¸ì‹! -> '{newly_recognized_word}'")

    cap.release()
    print("[ì‹œë®¬ë ˆì´ì…˜] ë¹„ë””ì˜¤ í”„ë ˆì„ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    # 6. (ì‹œë®¬ë ˆì´ì…˜) í´ë¼ì´ì–¸íŠ¸ê°€ ìµœì¢… ë²ˆì—­ ê²°ê³¼ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤.
    #    ì´ ê³¼ì •ì€ `/translate/translate_latest` APIë¥¼ í˜¸ì¶œí•˜ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤.
    print("\n[ì‹œë®¬ë ˆì´ì…˜] ìµœì¢… ë²ˆì—­ ê²°ê³¼ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤... (/translate_latest í˜¸ì¶œ)")
    final_sentence = recognizer.get_full_sentence()
    
    print("\n" + "="*50)
    print("ğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ğŸ‰")
    print(f"ìµœì¢… ì¸ì‹ëœ ë¬¸ì¥: {final_sentence}")
    print("="*50)
    
    # 7. (ì‹œë®¬ë ˆì´ì…˜) ê²°ê³¼ë¥¼ ë°›ì€ í›„ Recognizer ìƒíƒœê°€ ì´ˆê¸°í™”ë©ë‹ˆë‹¤.
    recognizer.reset()
    print(f"\n[ì‹œë®¬ë ˆì´ì…˜] Recognizer ìƒíƒœê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. í˜„ì¬ ë¬¸ì¥: '{recognizer.get_full_sentence()}'")


if __name__ == '__main__':
    run_streaming_simulation()