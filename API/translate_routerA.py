import os
import tempfile
from dotenv import load_dotenv
import deepl
from fastapi import APIRouter, Depends, File, Form, HTTPException, Query, Request, Response, UploadFile
from fastapi.responses import JSONResponse, StreamingResponse
from sqlalchemy.orm import Session
from DB_Table import Word
from core_method import get_db, verify_or_refresh_token

# --- ğŸ’¡ 1. ë¶ˆí•„ìš”í•œ import ì •ë¦¬ ë° ìƒˆë¡œìš´ í´ë˜ìŠ¤ ì¶”ê°€ ---
# ê¸°ì¡´ì˜ run_model, LSTM_frame ë“±ì„ ëª¨ë‘ ì§€ìš°ê³  OOP2ì˜ í´ë˜ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
# íŒŒì¼ ìœ„ì¹˜ê°€ model/LSTM/LSTM_video_OOP2.py ë¼ë©´ ì•„ë˜ ê²½ë¡œê°€ ë§ìŠµë‹ˆë‹¤.
from model.LSTM.LSTM_video_OOP2A import SignLanguageRecognizer, CONFIG

router = APIRouter()

load_dotenv(dotenv_path="deepl_api_key.env")
AUTH_KEY = os.getenv("DEEPL_API_KEY")
VIDEO_DIR = "video"

# --- ìˆ˜ì–´ â†’ í…ìŠ¤íŠ¸ (A ë°©ì‹: í†µ ë™ì˜ìƒ ì²˜ë¦¬) ---
@router.post("/translate/sign_to_text")
async def translate_sign_to_text(request: Request, response: Response, expected_word: str = Form(...), file: UploadFile = File(...), db: Session = Depends(get_db)):
    user_id = verify_or_refresh_token(request, response)

    # ì—…ë¡œë“œëœ ì˜ìƒ íŒŒì¼ì„ ì„œë²„ì— ì„ì‹œë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
        tmp.write(await file.read())
        video_path = tmp.name

    predicted_word = "ì¸ì‹ ì‹¤íŒ¨" # ê¸°ë³¸ê°’ ì„¤ì •
    try:

        current_config = CONFIG.copy()
        current_config["VIDEO_FILE_PATH"] = video_path

        # Recognizer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        recognizer = SignLanguageRecognizer(current_config)

        # Recognizer ì‹¤í–‰ ë° ê²°ê³¼ ë°˜í™˜
        predicted_word = recognizer.run()
        
        print(f"### ë””ë²„ê¹…: recognizer.run()ì˜ ì‹¤ì œ ë°˜í™˜ê°’: '{predicted_word}' (íƒ€ì…: {type(predicted_word)}) ###")

        print("ì˜ˆì¸¡ ê²°ê³¼:", predicted_word)
        print("ì‚¬ìš©ì ì •ë‹µ:", expected_word)
        

    except Exception as e:
        print(f"An error occurred during recognition: {e}")
        raise HTTPException(status_code=500, detail="ìˆ˜ì–´ ì¸ì‹ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if os.path.exists(video_path):
            os.remove(video_path)

    is_match = (predicted_word == expected_word)

    if not predicted_word or predicted_word in ['í•™ìŠµë˜ì§€ ì•Šì€ ë™ì‘ì…ë‹ˆë‹¤', 'ì¸ì‹ì‹¤íŒ¨ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”']:
        return {
            "korean": predicted_word or "ì¸ì‹ëœ ë‹¨ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.",
            "match": False,
        }

    return {
        "korean": predicted_word,
        "match": is_match,
    }


# --- í…ìŠ¤íŠ¸ â†’ ìˆ˜ì–´ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€) ---
@router.get("/translate/text_to_sign")
async def get_sign_animation(request: Request, response: Response, word_text: str = Query(..., description="ì…ë ¥ëœ í•œêµ­ì–´ ë‹¨ì–´"), db: Session = Depends(get_db)):
    user_id = verify_or_refresh_token(request, response)
    

    # mBERT ì´ìš©í•´ì„œ ë¬¸ì¥ -> list
    # ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
    words = []
    # ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
    
    from anime.motion_merge import check_merge, api_motion_merge
    
    try:
        motion_data = check_merge(words, send_type='api')
    except Exception as e:
        raise HTTPException(
            status_code=500, 
            detail=f'{e}' # í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ë³´ì—¬ì¤„ ë©”ì‹œì§€
        )
    
    frame_generator = api_motion_merge(*motion_data)
    frame_list = list(frame_generator)

    return JSONResponse(content={"frames": frame_list})
# --- ğŸ’¡ 3. B ë°©ì‹(í”„ë ˆì„ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬) ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸ëŠ” ëª¨ë‘ ì‚­ì œ ---
# "/translate/analyze_frames" ì™€ "/translate/translate_latest" ëŠ” A ë°©ì‹ë§Œ ì‚¬ìš©í•˜ë¯€ë¡œ ì‚­ì œí•©ë‹ˆë‹¤.