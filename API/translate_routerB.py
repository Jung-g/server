import os
from dotenv import load_dotenv
import deepl
from fastapi import APIRouter, Depends, Body, HTTPException, Query, Request, Response
from sqlalchemy.orm import Session
from core_method import get_db, verify_or_refresh_token
from typing import List
import numpy as np
import cv2
import base64

from cachetools import TTLCache


from model.LSTM.LSTM_video_OOP2B import SignLanguageRecognizer # íŒŒì¼ ì´ë¦„ê³¼ ê²½ë¡œ í™•ì¸!
from model.LSTM.LSTM_video_OOP2A import CONFIG # íŒŒì¼ ì´ë¦„ê³¼ ê²½ë¡œ í™•ì¸!

router = APIRouter()

load_dotenv(dotenv_path="deepl_api_key.env")
AUTH_KEY = os.getenv("DEEPL_API_KEY")

# --- ğŸ’¡ 2. ì‚¬ìš©ìë³„ Recognizer ê°ì²´ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ ---
# { "user_id": SignLanguageRecognizer_instance } í˜•íƒœë¡œ ì €ì¥ë©ë‹ˆë‹¤.
#user_recognizers = {}
user_recognizers = TTLCache(maxsize=100, ttl=300) 


def decode_base64_to_numpy(base64_string: str) -> np.ndarray:
    """Base64 ë¬¸ìì—´ì„ OpenCV ì´ë¯¸ì§€(Numpy ë°°ì—´)ë¡œ ë””ì½”ë”©í•©ë‹ˆë‹¤."""
    try:
        img_bytes = base64.b64decode(base64_string)
        np_arr = np.frombuffer(img_bytes, np.uint8)
        return cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
    except Exception:
        return None

# --- ğŸ’¡ 3. `/analyze_frames` ì—”ë“œí¬ì¸íŠ¸ ì¬êµ¬ì„± ---
@router.post("/translate/analyze_frames")
async def analyze_frames(request: Request, response: Response, frames: List[str] = Body(..., embed=True), db: Session = Depends(get_db)):
    user_id = verify_or_refresh_token(request, response)

    # í•´ë‹¹ ìœ ì €ì˜ Recognizer ê°ì²´ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    if user_id not in user_recognizers:
        print(f"--- New recognizer created for user: {user_id} ---")
        user_recognizers[user_id] = SignLanguageRecognizer(CONFIG)
    
    recognizer = user_recognizers[user_id]
    
    newly_recognized_words = []
    for base64_frame in frames:
        frame_np = decode_base64_to_numpy(base64_frame)
        if frame_np is None:
            continue
        
        # í”„ë ˆì„ í•˜ë‚˜ë¥¼ ì²˜ë¦¬í•˜ê³ , ìƒˆë¡œ ì¸ì‹ëœ ë‹¨ì–´ê°€ ìˆìœ¼ë©´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        result = recognizer.process_frame(frame_np)
        if result:
            newly_recognized_words.append(result)
            print(f"User {user_id} recognized new word: {result}")

    # ìƒˆë¡œ ì¸ì‹ëœ ë‹¨ì–´ë“¤ì„ í´ë¼ì´ì–¸íŠ¸ì— ì¦‰ì‹œ ë°˜í™˜ (ì„ íƒì‚¬í•­)
    return {"status": "processing"}

# --- ğŸ’¡ 4. `/translate/translate_latest` ì—”ë“œí¬ì¸íŠ¸ ì¬êµ¬ì„± ---
@router.get("/translate/translate_latest")
def translate_latest(request: Request, response: Response, db: Session = Depends(get_db)):
    user_id = verify_or_refresh_token(request, response)

    if user_id not in user_recognizers:
        return {"korean": "ë¶„ì„ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.", "english": "", "japanese": "", "chinese": ""}

    recognizer = user_recognizers[user_id]
    
    # Recognizer ê°ì²´ì—ì„œ ìµœì¢… ë¬¸ì¥ ê°€ì ¸ì˜¤ê¸°
    final_sentence = recognizer.get_full_sentence()
    
    
    if not final_sentence:
        return {"korean": "ì¸ì‹ëœ ë‹¨ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.", "english": "", "japanese": "", "chinese": ""}

    # DeepL ë²ˆì—­
    translator = deepl.Translator(AUTH_KEY)
    result = {
        "korean": final_sentence,
        "english": translator.translate_text(final_sentence, target_lang="EN-US").text,
        "japanese": translator.translate_text(final_sentence, target_lang="JA").text,
        "chinese": translator.translate_text(final_sentence, target_lang="ZH").text,
    }
    
    # ë‹¤ìŒ ë¬¸ì¥ ì¸ì‹ì„ ìœ„í•´ í•´ë‹¹ ìœ ì €ì˜ Recognizer ìƒíƒœ ì´ˆê¸°í™”
    recognizer.reset()
    print(f"--- Recognizer for user {user_id} has been reset. ---")

    return result