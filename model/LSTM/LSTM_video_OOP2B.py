# LSTM_video_OOP2.py (Bë°©ì‹ ì§€ì› ë²„ì „)

from collections import deque
import cv2
import mediapipe as mp
import numpy as np
import torch
import tensorflow as tf
import json
import os
from PIL import ImageFont, ImageDraw, Image


class FeatureExtractor:
    """
    Extracts pose and hand keypoints from video frames for sign language recognition.
    It calculates features for both word and fingerspelling models and detects movement.
    """
    def __init__(self):
        self.mp_pose = mp.solutions.pose
        self.mp_hands = mp.solutions.hands
        self.pose = self.mp_pose.Pose(model_complexity=0, min_detection_confidence=0.5, min_tracking_confidence=0.8)
        self.hands = self.mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.8)
        
        self.previous_features = None
        self.previous_velocity = None

    def _get_75d_hand_features(self, joint):
        """Helper function to generate 75-dimensional hand features for the word model."""
        v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19], :]
        v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], :]
        v = v2 - v1
        v = v / (np.linalg.norm(v, axis=1)[:, np.newaxis] + 1e-6)
        angle_v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19], :2]
        angle_v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], :2]
        angle_v = angle_v2 - angle_v1
        angle_v = angle_v / (np.linalg.norm(angle_v, axis=1)[:, np.newaxis] + 1e-6)
        angle = np.degrees(np.arccos(np.einsum('nt,nt->n',
            angle_v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], 
            angle_v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])))
        return np.concatenate([v.flatten(), angle])

    def _get_55d_hand_features(self, joint):
        """Helper function to generate 55-dimensional hand features for the fingerspelling model."""
        v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19], :2]
        v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], :2]
        v = v2 - v1
        v = v / (np.linalg.norm(v, axis=1)[:, np.newaxis] + 1e-6)
        angle = np.degrees(np.arccos(np.einsum('nt,nt->n',
            v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], 
            v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])))
        return np.concatenate([v.flatten(), angle])

    def extract(self, frame):
        """Processes a single frame to extract all required features."""
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results_pose = self.pose.process(frame_rgb)
        results_hands = self.hands.process(frame_rgb)
        
        num_hands_detected = 0
        if results_hands.multi_hand_landmarks:
            num_hands_detected = len(results_hands.multi_hand_landmarks)
        
        pose_features = np.zeros(16)
        word_model_features = np.zeros(166)
        
        if results_pose.pose_landmarks:
            pose_lm = results_pose.pose_landmarks.landmark
            shoulder_center_x = (pose_lm[11].x + pose_lm[12].x) / 2
            shoulder_center_y = (pose_lm[11].y + pose_lm[12].y) / 2
            shoulder_width = np.linalg.norm([pose_lm[11].x - pose_lm[12].x, pose_lm[11].y - pose_lm[12].y]) + 1e-6
            
            temp_pose_features = []
            for idx in [11, 12, 13, 14, 15, 16, 23, 24]:
                temp_pose_features.append((pose_lm[idx].x - shoulder_center_x) / shoulder_width)
                temp_pose_features.append((pose_lm[idx].y - shoulder_center_y) / shoulder_width)
            pose_features = np.array(temp_pose_features)

        left_hand_features, right_hand_features = np.zeros(75), np.zeros(75)
        alphabet_feature = None

        if results_hands.multi_hand_landmarks:
            for i, hand_landmarks in enumerate(results_hands.multi_hand_landmarks):
                handedness = results_hands.multi_handedness[i].classification[0].label
                joint = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark])
                
                hand_features_75d = self._get_75d_hand_features(joint)
                if handedness == "Left":
                    left_hand_features = hand_features_75d
                elif handedness == "Right":
                    right_hand_features = hand_features_75d
                    alphabet_feature = self._get_55d_hand_features(joint)

        word_model_features = np.concatenate([pose_features, left_hand_features, right_hand_features])

        if self.previous_features is None: self.previous_features = np.zeros_like(word_model_features)
        velocity = word_model_features - self.previous_features
        if self.previous_velocity is None: self.previous_velocity = np.zeros_like(velocity)
        acceleration = velocity - self.previous_velocity
        
        movement = np.sum(np.abs(velocity))
        self.previous_features = word_model_features
        self.previous_velocity = velocity

        dynamic_word_features = np.concatenate([word_model_features, velocity, acceleration])
        
        return dynamic_word_features, alphabet_feature, movement, num_hands_detected

    def close(self):
        self.pose.close()
        self.hands.close()
        
class Predictor:
    """
    Manages loading and running both the word (PyTorch) and 
    fingerspelling (TFLite) models.
    """
    def __init__(self, config):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # --- Word Model (PyTorch) ---
        self.word_model = torch.jit.load(os.path.join(config['MODEL_DIR'], "lstm_sign_language_model_scripted.pt")).to(self.device)
        self.word_model.eval()
        self.data_mean = np.load(os.path.join(config['MODEL_DIR'], "data_mean.npy"))
        self.data_std = np.load(os.path.join(config['MODEL_DIR'], "data_std.npy"))
        with open(os.path.join(config['MODEL_DIR'], "label_map.json"), 'r', encoding='utf-8') as f:
            self.word_labels_map = {v: k for k, v in json.load(f).items()}
        
        # --- Fingerspelling Model (TFLite) ---
        tflite_path = os.path.join(config['MODEL_DIR'], "multi_hand_gesture_classifier.tflite")
        self.alphabet_interpreter = tf.lite.Interpreter(model_path=tflite_path)
        self.alphabet_interpreter.allocate_tensors()
        self.alphabet_input_details = self.alphabet_interpreter.get_input_details()
        self.alphabet_output_details = self.alphabet_interpreter.get_output_details()
        self.alphabet_actions = ['ã„±', 'ã„´', 'ã„·', 'ã„¹', 'ã…', 'ã…‚', 'ã……', 'ã…‡', 'ã…ˆ', 'ã…Š', 'ã…‹', 'ã…Œ', 'ã…', 'ã…','ã…', 'ã…‘', 'ã…“', 'ã…•', 'ã…—', 'ã…›', 'ã…œ', 'ã… ', 'ã…¡', 'ã…£','ã…', 'ã…’', 'ã…”', 'ã…–', 'ã…¢', 'ã…š', 'ã…Ÿ']

        # --- Buffers and Parameters ---
        self.word_buffer = deque()
        self.word_history = []
        self.alphabet_buffer = deque(maxlen=config['SEQ_LEN_ALPHABET'])
        
        self.alphabet_confirm_buffer = deque(maxlen=5) # ìµœê·¼ 3ê°œ ì˜ˆì¸¡ ì €ì¥ìš© ë²„í¼
        self.last_confirmed_alphabet = None # ë§ˆì§€ë§‰ìœ¼ë¡œ ì¸ì‹ëœ ì§€ë¬¸ìë¥¼ ì €ì¥
        
        self.config = config
        
    def predict_word(self, features):
        self.word_buffer.append(features)
        
        if len(self.word_buffer) > self.config['SEQ_LEN_WORD']:
            self.word_buffer.popleft()

        if len(self.word_buffer) < self.config['SEQ_LEN_WORD']:
            return None, 0.0

        sequence = np.array(list(self.word_buffer))
        
        normalized_sequence = (sequence - self.data_mean) / (self.data_std + 1e-8)
        input_tensor = torch.tensor(normalized_sequence, dtype=torch.float32).unsqueeze(0).to(self.device)

        with torch.no_grad():
            probabilities = torch.softmax(self.word_model(input_tensor), dim=1)
        
        confidence, idx = torch.max(probabilities, 1)
        confidence_item = confidence.item()

        if confidence_item < self.config['CONF_THRESHOLD_WORD']:
            return None, 0.0
        
        label = self.word_labels_map.get(idx.item(), "Unknown")
        self.word_history.append(label)

        if len(self.word_history) > self.config['STABLE_THRESHOLD_WORD']:
            self.word_history.pop(0)

        if (len(self.word_history) == self.config['STABLE_THRESHOLD_WORD'] and
                len(set(self.word_history)) == 1):
            return self.word_history[0], confidence_item
        
        return None, 0.0

    def predict_fingerspelling(self, features):
        if features is None:
            self.alphabet_confirm_buffer.append(None)
            self.last_confirmed_alphabet = None 
            return None, 0.0

        self.alphabet_buffer.append(features)
        if len(self.alphabet_buffer) < self.config['SEQ_LEN_ALPHABET']:
            return None, 0.0

        input_data = np.expand_dims(np.array(self.alphabet_buffer, dtype=np.float32), axis=0)
        self.alphabet_interpreter.set_tensor(self.alphabet_input_details[0]['index'], input_data)
        self.alphabet_interpreter.invoke()
        y_pred = self.alphabet_interpreter.get_tensor(self.alphabet_output_details[0]['index'])

        i_pred = int(np.argmax(y_pred[0]))
        confidence = y_pred[0][i_pred]
        
        if confidence > self.config['CONF_THRESHOLD_ALPHABET']:
            self.alphabet_confirm_buffer.append(self.alphabet_actions[i_pred])
        else:
            self.alphabet_confirm_buffer.append(None)
            self.last_confirmed_alphabet = None

        if (len(self.alphabet_confirm_buffer) == self.alphabet_confirm_buffer.maxlen and
                len(set(self.alphabet_confirm_buffer)) == 1 and
                self.alphabet_confirm_buffer[0] is not None):

            current_stable_prediction = self.alphabet_confirm_buffer[0]

            if current_stable_prediction != self.last_confirmed_alphabet:
                self.last_confirmed_alphabet = current_stable_prediction
                return current_stable_prediction, confidence

        return None, 0.0
    
    def reset(self):
        """Resets all buffers and histories."""
        self.word_buffer.clear()
        self.word_history.clear()
        self.alphabet_buffer.clear()
        self.alphabet_confirm_buffer.clear()
        self.last_confirmed_alphabet = None

    def reset_word_buffer(self):
        """Resets only the word buffer."""
        self.word_buffer.clear()
        self.word_history.clear()
        
        
# --- ğŸ’¡ 1. `SignLanguageRecognizer` í´ë˜ìŠ¤ ëŒ€í­ ìˆ˜ì • ---
class SignLanguageRecognizer:
    def __init__(self, config):
        self.config = config
        self.feature_extractor = FeatureExtractor()
        self.predictor = Predictor(config)
        
        # ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
        self.sentence_words = []
        self.idle_counter = 0
        self.HAND_HISTORY_LENGTH = 15 
        self.hand_presence_history = deque(maxlen=self.HAND_HISTORY_LENGTH)
        # IDLE_TIME_THRESHOLD_FRAMESëŠ” ê³ ì •ê°’ í˜¹ì€ FPS ê¸°ë°˜ìœ¼ë¡œ ì„¤ì • (ì˜ˆ: 30fps ê¸°ì¤€ 2.5ì´ˆ = 75í”„ë ˆì„)
        self.IDLE_TIME_THRESHOLD_FRAMES = 75 

    def reset(self):
        """ì¸ì‹ê¸° ìƒíƒœë¥¼ ì™„ì „íˆ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        print("--- Recognizer state has been reset. ---")
        self.sentence_words.clear()
        self.idle_counter = 0
        self.hand_presence_history.clear()
        self.predictor.reset() # Predictor ë‚´ë¶€ ë²„í¼ë“¤ë„ ë¦¬ì…‹

    def process_frame(self, frame):
        """
        ë‹¨ì¼ í”„ë ˆì„ì„ ë°›ì•„ ì²˜ë¦¬í•˜ê³ , ìƒˆë¡œìš´ ë‹¨ì–´ê°€ ì¸ì‹ë˜ë©´ í•´ë‹¹ ë‹¨ì–´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        word_feats, alphabet_feats, movement, num_hands = self.feature_extractor.extract(frame)
        self.hand_presence_history.append(num_hands)

        # ìœ íœ´ ìƒíƒœ ê°ì§€
        if movement < self.config['MOVEMENT_THRESHOLD']:
            self.idle_counter += 1
        else:
            self.idle_counter = 0
        
        # ì¼ì • ì‹œê°„ ì›€ì§ì„ ì—†ìœ¼ë©´ ë¬¸ì¥ ì´ˆê¸°í™”
        if self.idle_counter >= self.IDLE_TIME_THRESHOLD_FRAMES:
            if self.sentence_words:
                print(f"IDLE - Resetting sentence: {' '.join(self.sentence_words)}")
            self.reset()
            return None # ìœ íœ´ ìƒíƒœì´ë¯€ë¡œ ì•„ë¬´ê²ƒë„ ë°˜í™˜ ì•ˆ í•¨

        predicted_word, word_conf = self.predictor.predict_word(word_feats)
        predicted_alphabet, alphabet_conf = self.predictor.predict_fingerspelling(alphabet_feats)

        newly_recognized_token = None

        # ì›ë³¸ì˜ ìš°ì„¸ íŒì • ë¡œì§ ì ìš©
        # ì§€ë¬¸ì ì‹ ë¢°ë„ê°€ 0.8 ì´ìƒì´ê³ , ë‹¨ì–´ ì‹ ë¢°ë„ë³´ë‹¤ 0.1(10%) ì´ìƒ ë†’ì„ ë•Œë§Œ ì§€ë¬¸ìë¡œ ì¸ì •
        if predicted_alphabet and alphabet_conf > self.config.get('CONF_THRESHOLD_ALPHABET', 0.8) and alphabet_conf > word_conf + 0.1:
            self.idle_counter = 0
            if not self.sentence_words or self.sentence_words[-1] != predicted_alphabet:
                self.sentence_words.append(predicted_alphabet)
                newly_recognized_token = predicted_alphabet
            
            # â— ë²„í¼ ì´ˆê¸°í™” ì „ëµ ë³€ê²½: ë‹¨ì–´ ë²„í¼ë§Œ ë¦¬ì…‹
            self.predictor.reset_word_buffer() 

        elif predicted_word and word_conf > self.config.get('CONF_THRESHOLD_WORD', 0.7):
            self.idle_counter = 0
            if not self.sentence_words or self.sentence_words[-1] != predicted_word:
                self.sentence_words.append(predicted_word)
                newly_recognized_token = predicted_word

            # â— ë²„í¼ ì´ˆê¸°í™” ì „ëµ ë³€ê²½: ë‹¨ì–´ ë²„í¼ë§Œ ë¦¬ì…‹
            self.predictor.reset_word_buffer()

        return newly_recognized_token # ìƒˆë¡œ ì¸ì‹ëœ ë‹¨ì–´/ì§€ë¬¸ì ë°˜í™˜ (ì—†ìœ¼ë©´ None)
    
    def get_full_sentence(self):
        """í˜„ì¬ê¹Œì§€ ì¸ì‹ëœ ì „ì²´ ë¬¸ì¥ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return " ".join(self.sentence_words)

    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.feature_extractor.close()

# --- ğŸ’¡ 2. ê¸°ì¡´ run() ë©”ì†Œë“œ ë° if __name__ == '__main__': ë¶€ë¶„ì€ í…ŒìŠ¤íŠ¸ìš©ì´ë¯€ë¡œ ì‚­ì œí•˜ê±°ë‚˜ ì£¼ì„ ì²˜ë¦¬ ---
# if __name__ == '__main__': ...