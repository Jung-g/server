# hong_translate_main.py

from js_korean_2_gloss.resource_loader import resources
from my_jamo import preprocess_input, assemble_jamos
from calculate_korean2gloss import calculate_similarity
from gemini_control import gemini_translate_control

def translate_pipeline(raw_text: str) -> list:
    """
    í•˜ë‚˜ì˜ ë¬¸ì¥ì„ ë°›ì•„ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ê³ ,
    ìµœì¢…ì ìœ¼ë¡œ ì™„ì„±ëœ ë¬¸ì¥ 'í•˜ë‚˜'ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    
    final_sentence_list = []
    
    # 1 & 2ë‹¨ê³„: ìëª¨ ì¡°ë¦½
    processed_jamo = preprocess_input(raw_text)
    gloss_sentence = assemble_jamos(processed_jamo)
    print(f" [ìëª¨ ì¡°ë¦½ ê²°ê³¼] {gloss_sentence}")

    # 3ë‹¨ê³„: í‘œì œì–´ -> KoBART ë³€í™˜
    kobart_sentence = gloss_to_natural_sentence(gloss_sentence)
    print(f" [KoBART ë³€í™˜] {kobart_sentence}")
    
    # 4ë‹¨ê³„: ìœ ì‚¬ë„ ê²€ì‚¬
    similarity = calculate_similarity(gloss_sentence, kobart_sentence)
    print(f" [ìœ ì‚¬ë„ ê²€ì‚¬] {similarity:.4f}")

    # ê¸°ë³¸ê°’ì€ KoBART ê²°ê³¼ë¡œ ì„¤ì •
    final_sentence = kobart_sentence

    # 5ë‹¨ê³„: ìœ ì‚¬ë„ ì ìˆ˜ì— ë”°ë¥¸ Gemini í˜¸ì¶œ
    if similarity <= 0.79:
        print("-" * 60)
        print(f"âš ï¸ ìœ ì‚¬ë„({similarity:.4f})ê°€ 0.8 ì´í•˜ì´ë¯€ë¡œ Gemini APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì¬ë²ˆì—­í•©ë‹ˆë‹¤.")
        gemini_result = gemini_translate_control(raw_text, gloss_sentence)
        
        if not gemini_result.startswith("[Error"):
            final_sentence = gemini_result
        else:
            print(f"ğŸš¨ Gemini í˜¸ì¶œ ì‹¤íŒ¨! KoBART ê²°ê³¼ë¥¼ ìµœì¢… ê²°ê³¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
    final_sentence_list.append(final_sentence)

    print(f"ìµœì¢… ë°˜í™˜ ë°ì´í„° : {final_sentence_list}")
    print(f"(íƒ€ì…: {type(final_sentence_list)})")
    
    return final_sentence_list

def gloss_to_natural_sentence(gloss_text: str) -> str:
    """KoBART ëª¨ë¸ë¡œ í‘œì œì–´ ë¬¸ì¥ì„ ìì—°ì–´ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    inputs = resources.kobart_g2s_tokenizer(gloss_text, return_tensors="pt", max_length=128, truncation=True)
    output_tokens = resources.kobart_g2s_model.generate(
        inputs.input_ids, max_length=128, num_beams=5, early_stopping=True
    )
    return resources.kobart_g2s_tokenizer.decode(output_tokens[0], skip_special_tokens=True)